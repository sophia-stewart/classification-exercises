{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c760221",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises\n",
    "\n",
    "#### Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd502c3",
   "metadata": {},
   "source": [
    "#### 1. What is your baseline prediction? What is your baseline accuracy? *remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d04385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2c099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare  embark_town  \\\n",
       "513         1       1  female  54.0      1      0  59.4000    Cherbourg   \n",
       "169         0       3    male  28.0      0      0  56.4958  Southampton   \n",
       "276         0       3  female  45.0      0      0   7.7500  Southampton   \n",
       "541         0       3  female   9.0      4      2  31.2750  Southampton   \n",
       "406         0       3    male  51.0      0      0   7.7500  Southampton   \n",
       "\n",
       "     alone  embark_town_Queenstown  embark_town_Southampton  sex_male  \n",
       "513      0                       0                        0         0  \n",
       "169      1                       0                        1         1  \n",
       "276      1                       0                        1         0  \n",
       "541      0                       0                        1         0  \n",
       "406      1                       0                        1         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read titanic data into dataframe\n",
    "titanic = acquire.get_titanic_data()\n",
    "# clean and split data\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace3b681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    220\n",
       "1    157\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine most prevalent class\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40b799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y versions of train, validate, and test samples\n",
    "x_train = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train = train.survived\n",
    "\n",
    "x_validate = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "x_test = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66f4429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.583554376657825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create baseline\n",
    "baseline = 0\n",
    "# boolean mask of where baseline was correct\n",
    "matches_baseline = y_train == baseline\n",
    "# calculate baseline accuracy\n",
    "baseline_accuracy = matches_baseline.mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c34dd3",
   "metadata": {},
   "source": [
    "Our baseline prediction is 0 (did not survive). Our baseline accuracy is about 58.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59762674",
   "metadata": {},
   "source": [
    "#### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6520b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c2161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e693412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_train_decision_tree.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(tree, feature_names=x_train.columns, class_names=['not survived', 'survived'], rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "graph.render('titanic_train_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b85b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tree.predict(x_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a699fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03614458, 0.96385542],\n",
       "       [0.89808917, 0.10191083],\n",
       "       [0.45283019, 0.54716981],\n",
       "       [0.45283019, 0.54716981],\n",
       "       [0.89808917, 0.10191083]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = tree.predict_proba(x_train)\n",
    "y_pred_prob[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b4b35",
   "metadata": {},
   "source": [
    "#### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f44705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830238726790451"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ef9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  193   27\n",
       "1   37  120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_train, y_pred)\n",
    "pd.DataFrame(sklearn.metrics.confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ab6d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       220\n",
      "           1       0.82      0.76      0.79       157\n",
      "\n",
      "    accuracy                           0.83       377\n",
      "   macro avg       0.83      0.82      0.82       377\n",
      "weighted avg       0.83      0.83      0.83       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31753ab",
   "metadata": {},
   "source": [
    "#### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770fec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.02%\n",
      "True Positive Rate: 76.43%\n",
      "True Negative Rate: 87.73%\n",
      "False Positive Rate: 12.27%\n",
      "False Negative Rate: 23.57%\n",
      "Precision: 81.63%\n",
      "Recall: 76.43%\n",
      "F1 Score: 78.95%\n",
      "Support - 1: 157\n",
      "Support - 0: 220\n"
     ]
    }
   ],
   "source": [
    "# with 1 being positive and 0 being negative\n",
    "TP = 120\n",
    "TN = 193\n",
    "FP = 27\n",
    "FN = 37\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "true_pos_rate = TP/(TP+FN)\n",
    "print(f'True Positive Rate: {true_pos_rate:.2%}')\n",
    "true_neg_rate = TN/(TN+FP)\n",
    "print(f'True Negative Rate: {true_neg_rate:.2%}')\n",
    "false_pos_rate = FP/(FP+TN)\n",
    "print(f'False Positive Rate: {false_pos_rate:.2%}')\n",
    "false_neg_rate = FN/(FN+TP)\n",
    "print(f'False Negative Rate: {false_neg_rate:.2%}')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision: {precision:.2%}')\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Recall: {recall:.2%}')\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f'F1 Score: {f1_score:.2%}')\n",
    "support_1 = TP+FN\n",
    "print(f'Support - 1: {support_1}')\n",
    "support_0 = TN+FP\n",
    "print(f'Support - 0: {support_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b4213",
   "metadata": {},
   "source": [
    "#### 5. Run through steps 2-4 using a different `max_depth` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c8a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       220\n",
      "           1       0.84      0.76      0.80       157\n",
      "\n",
      "    accuracy                           0.84       377\n",
      "   macro avg       0.84      0.83      0.83       377\n",
      "weighted avg       0.84      0.84      0.84       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree2 = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "tree2 = tree2.fit(x_train, y_train)\n",
    "dot_data = export_graphviz(tree2, feature_names=x_train.columns, class_names=['not survived', 'survived'], rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('titanic_train_decision_tree2', view=True)\n",
    "y_pred = tree2.predict(x_train)\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3b1d2",
   "metadata": {},
   "source": [
    "#### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4589f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3\n",
      "In-Sample Accuracy: 83.02%\n",
      "\n",
      "Max Depth: 4\n",
      "In-Sample Accuracy: 83.82%\n"
     ]
    }
   ],
   "source": [
    "print('Max Depth: 3')\n",
    "print(f'In-Sample Accuracy: {tree.score(x_train, y_train):.2%}')\n",
    "print()\n",
    "print('Max Depth: 4')\n",
    "print(f'In-Sample Accuracy: {tree2.score(x_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7cf41",
   "metadata": {},
   "source": [
    "The model with a max depth of 4 works better (more accurate by 0.8%) on the in-sample data than the model with a max depth of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57174dd",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on your out-of-sample data, the `validate` set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2145bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3\n",
      "Out-of-Sample Accuracy: 77.16%\n",
      "\n",
      "Max Depth: 4\n",
      "Out-of-Sample Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "print('Max Depth: 3')\n",
    "print(f'Out-of-Sample Accuracy: {tree.score(x_validate, y_validate):.2%}')\n",
    "print()\n",
    "print('Max Depth: 4')\n",
    "print(f'Out-of-Sample Accuracy: {tree2.score(x_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0119b",
   "metadata": {},
   "source": [
    "The model with a max depth of 4 performs better (more accurate by 0.62%) than the model with a max depth of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "942f2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.830239</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.058634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.838196</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.060419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.859416</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.063120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.888594</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.160199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.925729</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.154125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.187739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.976127</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.210695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.984085</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.212480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.992042</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.208092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.235436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.244261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           3        0.830239           0.771605    0.058634\n",
       "1           4        0.838196           0.777778    0.060419\n",
       "2           5        0.859416           0.796296    0.063120\n",
       "3           6        0.888594           0.728395    0.160199\n",
       "4           7        0.925729           0.771605    0.154125\n",
       "5           8        0.965517           0.777778    0.187739\n",
       "6           9        0.976127           0.765432    0.210695\n",
       "7          10        0.984085           0.771605    0.212480\n",
       "8          11        0.992042           0.783951    0.208092\n",
       "9          12        0.994695           0.759259    0.235436\n",
       "10         13        0.997347           0.753086    0.244261\n",
       "11         14        0.997347           0.753086    0.244261\n",
       "12         15        0.997347           0.753086    0.244261\n",
       "13         16        0.997347           0.753086    0.244261\n",
       "14         17        0.997347           0.753086    0.244261\n",
       "15         18        0.997347           0.753086    0.244261\n",
       "16         19        0.997347           0.753086    0.244261\n",
       "17         20        0.997347           0.753086    0.244261"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using method from review to try out several max_depth values:\n",
    "# use for loop, dictionary, and dataframe to view accuracies/differences in train/validate accuracy\n",
    "scores = []\n",
    "for n in range(3, 21):\n",
    "    tree = DecisionTreeClassifier(max_depth=n, random_state=123)\n",
    "    tree = tree.fit(x_train, y_train)\n",
    "    accuracy_train = tree.score(x_train, y_train)\n",
    "    accuracy_validate = tree.score(x_validate, y_validate)\n",
    "    output = {'max_depth':n,\n",
    "              'train_accuracy':accuracy_train,\n",
    "              'validate_accuracy':accuracy_validate}\n",
    "    scores.append(output)\n",
    "decision_trees = pd.DataFrame(scores)\n",
    "decision_trees['difference'] = decision_trees.train_accuracy - decision_trees.validate_accuracy\n",
    "decision_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c87ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.859416</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.063120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.838196</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.060419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.830239</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.058634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "2          5        0.859416           0.796296    0.063120\n",
       "1          4        0.838196           0.777778    0.060419\n",
       "0          3        0.830239           0.771605    0.058634"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# narrow results to those with a train/validate difference below 0.1 (to avoid choosing an overfit model)\n",
    "# sort by validate_accuracy and then by difference;\n",
    "# want to see most accurate model on out-of-sample data \n",
    "# and one with lowest difference if models have same validate_accuracy\n",
    "decision_trees[decision_trees.difference<=0.1].sort_values(by=['validate_accuracy', 'difference'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219d3d4",
   "metadata": {},
   "source": [
    "When looking at decision tree models with max depths ranging from 3 to 20, the model with a max depth of 5 appears to be the model which performs best with the titanic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e3ba8",
   "metadata": {},
   "source": [
    "------------------------\n",
    "\n",
    "#### Bonus:\n",
    "\n",
    "#### 1. Work through these same exercises using the Telco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a9b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3cc2080",
   "metadata": {},
   "source": [
    "#### 2. Experiment with this model on other datasets with a higher number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af609462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "331c4cbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Random Forest Exercises\n",
    "\n",
    "#### Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "#### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee806d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6d0a3",
   "metadata": {},
   "source": [
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defb8bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814323607427056"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8426a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  218    2\n",
       "1    5  152"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=sorted(y_train.unique())\n",
    "pd.DataFrame(sklearn.metrics.confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "846d156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       220\n",
      "           1       0.99      0.97      0.98       157\n",
      "\n",
      "    accuracy                           0.98       377\n",
      "   macro avg       0.98      0.98      0.98       377\n",
      "weighted avg       0.98      0.98      0.98       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c058add",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "872aec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.14%\n",
      "True Positive Rate: 96.82%\n",
      "False Positive Rate: 0.91%\n",
      "True Negative Rate: 99.09%\n",
      "False Negative Rate: 3.18%\n",
      "Precision: 98.70%\n",
      "Recall: 96.82%\n",
      "F1 Score: 97.75%\n",
      "Support - 1: 157\n",
      "Support - 0: 220\n"
     ]
    }
   ],
   "source": [
    "TP = 152\n",
    "TN = 218\n",
    "FP = 2\n",
    "FN = 5\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "true_pos_rate = TP/(TP+FN)\n",
    "print(f'True Positive Rate: {true_pos_rate:.2%}')\n",
    "false_pos_rate = FP/(FP+TN)\n",
    "print(f'False Positive Rate: {false_pos_rate:.2%}')\n",
    "true_neg_rate = TN/(TN+FP)\n",
    "print(f'True Negative Rate: {true_neg_rate:.2%}')\n",
    "false_neg_rate = FN/(FN+TP)\n",
    "print(f'False Negative Rate: {false_neg_rate:.2%}')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision: {precision:.2%}')\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Recall: {recall:.2%}')\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f'F1 Score: {f1_score:.2%}')\n",
    "support_1 = TP+FN\n",
    "print(f'Support - 1: {support_1}')\n",
    "support_0 = TN+FP\n",
    "print(f'Support - 0: {support_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599ed81",
   "metadata": {},
   "source": [
    "#### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60525055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with min of 2 samples per leaf and max depth of 1:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.740876    0.834951  0.766578    0.787914      0.780053\n",
      "recall       0.922727    0.547771  0.766578    0.735249      0.766578\n",
      "f1-score     0.821862    0.661538  0.766578    0.741700      0.755096\n",
      "support    220.000000  157.000000  0.766578  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 2:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.779528    0.821138  0.793103    0.800333      0.796856\n",
      "recall       0.900000    0.643312  0.793103    0.771656      0.793103\n",
      "f1-score     0.835443    0.721429  0.793103    0.778436      0.787962\n",
      "support    220.000000  157.000000  0.793103  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 3:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.814516    0.860465  0.830239    0.837491      0.833651\n",
      "recall       0.918182    0.707006  0.830239    0.812594      0.830239\n",
      "f1-score     0.863248    0.776224  0.830239    0.819736      0.827007\n",
      "support    220.000000  157.000000  0.830239  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 4:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.834008    0.892308  0.854111    0.863158      0.858287\n",
      "recall       0.936364    0.738854  0.854111    0.837609      0.854111\n",
      "f1-score     0.882227    0.808362  0.854111    0.845295      0.851466\n",
      "support    220.000000  157.000000  0.854111  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 5:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.850202    0.923077  0.875332    0.886640      0.880551\n",
      "recall       0.954545    0.764331  0.875332    0.859438      0.875332\n",
      "f1-score     0.899358    0.836237  0.875332    0.867797      0.873071\n",
      "support    220.000000  157.000000  0.875332  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 6:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.868852    0.939850  0.893899    0.904351      0.898419\n",
      "recall       0.963636    0.796178  0.893899    0.879907      0.893899\n",
      "f1-score     0.913793    0.862069  0.893899    0.887931      0.892253\n",
      "support    220.000000  157.000000  0.893899  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 7:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.886555    0.935252  0.904509    0.910903      0.906834\n",
      "recall       0.959091    0.828025  0.904509    0.893558      0.904509\n",
      "f1-score     0.921397    0.878378  0.904509    0.899888      0.903482\n",
      "support    220.000000  157.000000  0.904509  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 8:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.886555    0.935252  0.904509    0.910903      0.906834\n",
      "recall       0.959091    0.828025  0.904509    0.893558      0.904509\n",
      "f1-score     0.921397    0.878378  0.904509    0.899888      0.903482\n",
      "support    220.000000  157.000000  0.904509  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 2 samples per leaf and max depth of 9:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.889831    0.929078  0.904509    0.909454      0.906175\n",
      "recall       0.954545    0.834395  0.904509    0.894470      0.904509\n",
      "f1-score     0.921053    0.879195  0.904509    0.900124      0.903621\n",
      "support    220.000000  157.000000  0.904509  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 1:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.740876    0.834951  0.766578    0.787914      0.780053\n",
      "recall       0.922727    0.547771  0.766578    0.735249      0.766578\n",
      "f1-score     0.821862    0.661538  0.766578    0.741700      0.755096\n",
      "support    220.000000  157.000000  0.766578  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 2:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.779528    0.821138  0.793103    0.800333      0.796856\n",
      "recall       0.900000    0.643312  0.793103    0.771656      0.793103\n",
      "f1-score     0.835443    0.721429  0.793103    0.778436      0.787962\n",
      "support    220.000000  157.000000  0.793103  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 3:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.817073    0.854962  0.830239    0.836018      0.832852\n",
      "recall       0.913636    0.713376  0.830239    0.813506      0.830239\n",
      "f1-score     0.862661    0.777778  0.830239    0.820219      0.827312\n",
      "support    220.000000  157.000000  0.830239  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 4:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.830645    0.891473  0.851459    0.861059      0.855977\n",
      "recall       0.936364    0.732484  0.851459    0.834424      0.851459\n",
      "f1-score     0.880342    0.804196  0.851459    0.842269      0.848631\n",
      "support    220.000000  157.000000  0.851459  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 5:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.832669    0.912698  0.859416    0.872684      0.865997\n",
      "recall       0.950000    0.732484  0.859416    0.841242      0.859416\n",
      "f1-score     0.887473    0.812721  0.859416    0.850097      0.856343\n",
      "support    220.000000  157.000000  0.859416  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 6:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.875519    0.933824  0.896552    0.904671      0.899799\n",
      "recall       0.959091    0.808917  0.896552    0.884004      0.896552\n",
      "f1-score     0.915401    0.866894  0.896552    0.891148      0.895201\n",
      "support    220.000000  157.000000  0.896552  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 7:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.867769    0.925926  0.888594    0.896847      0.891988\n",
      "recall       0.954545    0.796178  0.888594    0.875362      0.888594\n",
      "f1-score     0.909091    0.856164  0.888594    0.882628      0.887050\n",
      "support    220.000000  157.000000  0.888594  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 8:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.878151    0.920863  0.893899    0.899507      0.895939\n",
      "recall       0.950000    0.815287  0.893899    0.882643      0.893899\n",
      "f1-score     0.912664    0.864865  0.893899    0.888764      0.892758\n",
      "support    220.000000  157.000000  0.893899  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 3 samples per leaf and max depth of 9:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.874477    0.920290  0.891247    0.897383      0.893556\n",
      "recall       0.950000    0.808917  0.891247    0.879459      0.891247\n",
      "f1-score     0.910675    0.861017  0.891247    0.885846      0.889995\n",
      "support    220.000000  157.000000  0.891247  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 1:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.740876    0.834951  0.766578    0.787914      0.780053\n",
      "recall       0.922727    0.547771  0.766578    0.735249      0.766578\n",
      "f1-score     0.821862    0.661538  0.766578    0.741700      0.755096\n",
      "support    220.000000  157.000000  0.766578  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 2:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.779528    0.821138  0.793103    0.800333      0.796856\n",
      "recall       0.900000    0.643312  0.793103    0.771656      0.793103\n",
      "f1-score     0.835443    0.721429  0.793103    0.778436      0.787962\n",
      "support    220.000000  157.000000  0.793103  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 3:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.813765    0.853846  0.827586    0.833806      0.830457\n",
      "recall       0.913636    0.707006  0.827586    0.810321      0.827586\n",
      "f1-score     0.860814    0.773519  0.827586    0.817166      0.824460\n",
      "support    220.000000  157.000000  0.827586  377.000000    377.000000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with min of 4 samples per leaf and max depth of 4:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.837398    0.893130  0.856764    0.865264      0.860607\n",
      "recall       0.936364    0.745223  0.856764    0.840793      0.856764\n",
      "f1-score     0.884120    0.812500  0.856764    0.848310      0.854294\n",
      "support    220.000000  157.000000  0.856764  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 5:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.826772    0.918699  0.856764    0.872735      0.865054\n",
      "recall       0.954545    0.719745  0.856764    0.837145      0.856764\n",
      "f1-score     0.886076    0.807143  0.856764    0.846609      0.853205\n",
      "support    220.000000  157.000000  0.856764  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 6:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.856557    0.917293  0.877984    0.886925      0.881851\n",
      "recall       0.950000    0.777070  0.877984    0.863535      0.877984\n",
      "f1-score     0.900862    0.841379  0.877984    0.871121      0.876091\n",
      "support    220.000000  157.000000  0.877984  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 7:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.864198    0.925373  0.885942    0.894785      0.889674\n",
      "recall       0.954545    0.789809  0.885942    0.872177      0.885942\n",
      "f1-score     0.907127    0.852234  0.885942    0.879681      0.884267\n",
      "support    220.000000  157.000000  0.885942  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 8:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.867220    0.919118  0.885942    0.893169      0.888832\n",
      "recall       0.950000    0.796178  0.885942    0.873089      0.885942\n",
      "f1-score     0.906725    0.853242  0.885942    0.879983      0.884452\n",
      "support    220.000000  157.000000  0.885942  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 4 samples per leaf and max depth of 9:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.867220    0.919118  0.885942    0.893169      0.888832\n",
      "recall       0.950000    0.796178  0.885942    0.873089      0.885942\n",
      "f1-score     0.906725    0.853242  0.885942    0.879983      0.884452\n",
      "support    220.000000  157.000000  0.885942  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 1:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.740876    0.834951  0.766578    0.787914      0.780053\n",
      "recall       0.922727    0.547771  0.766578    0.735249      0.766578\n",
      "f1-score     0.821862    0.661538  0.766578    0.741700      0.755096\n",
      "support    220.000000  157.000000  0.766578  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 2:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.779528    0.821138  0.793103    0.800333      0.796856\n",
      "recall       0.900000    0.643312  0.793103    0.771656      0.793103\n",
      "f1-score     0.835443    0.721429  0.793103    0.778436      0.787962\n",
      "support    220.000000  157.000000  0.793103  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 3:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.813008    0.847328  0.824934    0.830168      0.827301\n",
      "recall       0.909091    0.707006  0.824934    0.808049      0.824934\n",
      "f1-score     0.858369    0.770833  0.824934    0.814601      0.821915\n",
      "support    220.000000  157.000000  0.824934  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 4:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.837398    0.893130  0.856764    0.865264      0.860607\n",
      "recall       0.936364    0.745223  0.856764    0.840793      0.856764\n",
      "f1-score     0.884120    0.812500  0.856764    0.848310      0.854294\n",
      "support    220.000000  157.000000  0.856764  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 5:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829365    0.912000  0.856764    0.870683      0.863778\n",
      "recall       0.950000    0.726115  0.856764    0.838057      0.856764\n",
      "f1-score     0.885593    0.808511  0.856764    0.847052      0.853493\n",
      "support    220.000000  157.000000  0.856764  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 6:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.846774    0.922481  0.872679    0.884627      0.878302\n",
      "recall       0.954545    0.757962  0.872679    0.856254      0.872679\n",
      "f1-score     0.897436    0.832168  0.872679    0.864802      0.870255\n",
      "support    220.000000  157.000000  0.872679  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 7:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.856557    0.917293  0.877984    0.886925      0.881851\n",
      "recall       0.950000    0.777070  0.877984    0.863535      0.877984\n",
      "f1-score     0.900862    0.841379  0.877984    0.871121      0.876091\n",
      "support    220.000000  157.000000  0.877984  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 8:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.853659    0.923664  0.877984    0.888661      0.882812\n",
      "recall       0.954545    0.770701  0.877984    0.862623      0.877984\n",
      "f1-score     0.901288    0.840278  0.877984    0.870783      0.875880\n",
      "support    220.000000  157.000000  0.877984  377.000000    377.000000\n",
      "\n",
      "Random Forest with min of 5 samples per leaf and max depth of 9:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.860656    0.924812  0.883289    0.892734      0.887373\n",
      "recall       0.954545    0.783439  0.883289    0.868992      0.883289\n",
      "f1-score     0.905172    0.848276  0.883289    0.876724      0.881478\n",
      "support    220.000000  157.000000  0.883289  377.000000    377.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(2, 6):\n",
    "    for i in range(1, 10):\n",
    "        rf = RandomForestClassifier(min_samples_leaf=n, max_depth=i, random_state=123)\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_train)\n",
    "        class_report = sklearn.metrics.classification_report(y_train, y_pred, output_dict=True)\n",
    "        print(f'Random Forest with min of {n} samples per leaf and max depth of {i}:')\n",
    "        print(pd.DataFrame(class_report))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87a717",
   "metadata": {},
   "source": [
    "#### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840d43d",
   "metadata": {},
   "source": [
    "The best performing model (accuracy=90.45%) on the in-sample data is the random forest with min_samples_leaf=2 and max_depth=7. After that, the random forests with min_samples_leaf=2, max_depth=6 and min_samples_leaf=3, max_depth=8 perform best with an accuracy of 89.39%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a27921",
   "metadata": {},
   "source": [
    "#### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e07cb6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf=2, max_depth=7\n",
      "Train Accuracy: 90.45%\n",
      "Validate Accuracy: 81.48%\n",
      "Difference: 8.97%\n",
      "\n",
      "min_samples_leaf=2, max_depth=6\n",
      "Train Accuracy: 89.39%\n",
      "Validate Accuracy: 80.86%\n",
      "Difference: 8.53%\n",
      "\n",
      "min_samples_leaf=3, max_depth=8\n",
      "Train Accuracy: 89.39%\n",
      "Validate Accuracy: 80.86%\n",
      "Difference: 8.53%\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(min_samples_leaf=2, max_depth=7, random_state=123)\n",
    "rf1.fit(x_train, y_train)\n",
    "print('min_samples_leaf=2, max_depth=7')\n",
    "print(f'Train Accuracy: {rf1.score(x_train, y_train):.2%}')\n",
    "print(f'Validate Accuracy: {rf1.score(x_validate, y_validate):.2%}')\n",
    "print(f'Difference: {(rf1.score(x_train, y_train)-rf1.score(x_validate, y_validate)):.2%}\\n')\n",
    "rf2 = RandomForestClassifier(min_samples_leaf=2, max_depth=6, random_state=123)\n",
    "rf2.fit(x_train, y_train)\n",
    "print('min_samples_leaf=2, max_depth=6')\n",
    "print(f'Train Accuracy: {rf2.score(x_train, y_train):.2%}')\n",
    "print(f'Validate Accuracy: {rf2.score(x_validate, y_validate):.2%}')\n",
    "print(f'Difference: {(rf2.score(x_train, y_train)-rf2.score(x_validate, y_validate)):.2%}\\n')\n",
    "rf3 = RandomForestClassifier(min_samples_leaf=3, max_depth=8, random_state=123)\n",
    "rf3.fit(x_train, y_train)\n",
    "print('min_samples_leaf=3, max_depth=8')\n",
    "print(f'Train Accuracy: {rf3.score(x_train, y_train):.2%}')\n",
    "print(f'Validate Accuracy: {rf3.score(x_validate, y_validate):.2%}')\n",
    "print(f'Difference: {(rf3.score(x_train, y_train)-rf3.score(x_validate, y_validate)):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5c344",
   "metadata": {},
   "source": [
    "The model with min_samples_leaf=2, max_depth=7 performs better than the other models on both the train and validate samples. However, the other two models have the same accuracy on both train and validate and also have a slightly smaller difference between their train accuracy and their validate accuracy than the best-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8ea65",
   "metadata": {},
   "source": [
    "---\n",
    "# K-Nearest Neighbor Exercises\n",
    "\n",
    "#### Continue working in your `model` file with the titanic dataset.\n",
    "\n",
    "#### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf7e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# create object\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe5f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aab1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = knn.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74666f",
   "metadata": {},
   "source": [
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21c4f519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973474801061007"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b794dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  220    0\n",
       "1    1  156"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sklearn.metrics.confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "599d8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       220\n",
      "           1       1.00      0.99      1.00       157\n",
      "\n",
      "    accuracy                           1.00       377\n",
      "   macro avg       1.00      1.00      1.00       377\n",
      "weighted avg       1.00      1.00      1.00       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16834aa9",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b44e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 0, 1, 156)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = sklearn.metrics.confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60eba030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.73%\n",
      "True Positive Rate: 99.36%\n",
      "True Negative Rate: 100.00%\n",
      "False Positive Rate: 0.00%\n",
      "False Negative Rate: 0.64%\n",
      "Precision: 100.00%\n",
      "Recall: 99.36%\n",
      "F1 Score: 99.68%\n",
      "Support - 1: 157\n",
      "Support - 0: 220\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "true_pos_rate = TP/(TP+FN)\n",
    "print(f'True Positive Rate: {true_pos_rate:.2%}')\n",
    "true_neg_rate = TN/(TN+FP)\n",
    "print(f'True Negative Rate: {true_neg_rate:.2%}')\n",
    "false_pos_rate = FP/(FP+TN)\n",
    "print(f'False Positive Rate: {false_pos_rate:.2%}')\n",
    "false_neg_rate = FN/(FN+TP)\n",
    "print(f'False Negative Rate: {false_neg_rate:.2%}')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision: {precision:.2%}')\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Recall: {recall:.2%}')\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f'F1 Score: {f1_score:.2%}')\n",
    "support_1 = TP+FN\n",
    "print(f'Support - 1: {support_1}')\n",
    "support_0 = TN+FP\n",
    "print(f'Support - 0: {support_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b222c2",
   "metadata": {},
   "source": [
    "#### 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34e4461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy where k=10: 72.41%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       220\n",
      "           1       0.76      0.49      0.60       157\n",
      "\n",
      "    accuracy                           0.72       377\n",
      "   macro avg       0.74      0.69      0.69       377\n",
      "weighted avg       0.73      0.72      0.71       377\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  196  24\n",
       "1   80  77"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "knn10.fit(x_train, y_train)\n",
    "y_pred10 = knn10.predict(x_train)\n",
    "print(f'KNN Accuracy where k=10: {knn10.score(x_train, y_train):.2%}')\n",
    "print()\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred10))\n",
    "pd.DataFrame(sklearn.metrics.confusion_matrix(y_train, y_pred10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24302070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.41%\n",
      "True Positive Rate: 49.04%\n",
      "True Negative Rate: 89.09%\n",
      "False Positive Rate: 10.91%\n",
      "False Negative Rate: 50.96%\n",
      "Precision: 76.24%\n",
      "Recall: 49.04%\n",
      "F1 Score: 59.69%\n",
      "Support - 1: 157\n",
      "Support - 0: 220\n"
     ]
    }
   ],
   "source": [
    "TP = 77\n",
    "TN = 196\n",
    "FP = 24\n",
    "FN = 80\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "true_pos_rate = TP/(TP+FN)\n",
    "print(f'True Positive Rate: {true_pos_rate:.2%}')\n",
    "true_neg_rate = TN/(TN+FP)\n",
    "print(f'True Negative Rate: {true_neg_rate:.2%}')\n",
    "false_pos_rate = FP/(FP+TN)\n",
    "print(f'False Positive Rate: {false_pos_rate:.2%}')\n",
    "false_neg_rate = FN/(FN+TP)\n",
    "print(f'False Negative Rate: {false_neg_rate:.2%}')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision: {precision:.2%}')\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Recall: {recall:.2%}')\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f'F1 Score: {f1_score:.2%}')\n",
    "support_1 = TP+FN\n",
    "print(f'Support - 1: {support_1}')\n",
    "support_0 = TN+FP\n",
    "print(f'Support - 0: {support_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a18fa6",
   "metadata": {},
   "source": [
    "#### 5. Run through steps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f60436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy where k=20: 68.44%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76       220\n",
      "           1       0.69      0.43      0.53       157\n",
      "\n",
      "    accuracy                           0.68       377\n",
      "   macro avg       0.69      0.65      0.65       377\n",
      "weighted avg       0.69      0.68      0.67       377\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  190  30\n",
       "1   89  68"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn20 = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "knn20.fit(x_train, y_train)\n",
    "y_pred20 = knn20.predict(x_train)\n",
    "print(f'KNN Accuracy where k=20: {knn20.score(x_train, y_train):.2%}')\n",
    "print()\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred20))\n",
    "pd.DataFrame(sklearn.metrics.confusion_matrix(y_train, y_pred20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f201e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.44%\n",
      "True Positive Rate: 43.31%\n",
      "True Negative Rate: 86.36%\n",
      "False Positive Rate: 13.64%\n",
      "False Negative Rate: 56.69%\n",
      "Precision: 69.39%\n",
      "Recall: 43.31%\n",
      "F1 Score: 53.33%\n",
      "Support - 1: 157\n",
      "Support - 0: 220\n"
     ]
    }
   ],
   "source": [
    "TP = 68\n",
    "TN = 190\n",
    "FP = 30\n",
    "FN = 89\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "true_pos_rate = TP/(TP+FN)\n",
    "print(f'True Positive Rate: {true_pos_rate:.2%}')\n",
    "true_neg_rate = TN/(TN+FP)\n",
    "print(f'True Negative Rate: {true_neg_rate:.2%}')\n",
    "false_pos_rate = FP/(FP+TN)\n",
    "print(f'False Positive Rate: {false_pos_rate:.2%}')\n",
    "false_neg_rate = FN/(FN+TP)\n",
    "print(f'False Negative Rate: {false_neg_rate:.2%}')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision: {precision:.2%}')\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Recall: {recall:.2%}')\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f'F1 Score: {f1_score:.2%}')\n",
    "support_1 = TP+FN\n",
    "print(f'Support - 1: {support_1}')\n",
    "support_0 = TN+FP\n",
    "print(f'Support - 0: {support_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa39f1",
   "metadata": {},
   "source": [
    "#### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03cfe31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports of KNN classifiers on train set:\n",
      "\n",
      "k=5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       220\n",
      "           1       1.00      0.99      1.00       157\n",
      "\n",
      "    accuracy                           1.00       377\n",
      "   macro avg       1.00      1.00      1.00       377\n",
      "weighted avg       1.00      1.00      1.00       377\n",
      "\n",
      "\n",
      "k=10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       220\n",
      "           1       0.76      0.49      0.60       157\n",
      "\n",
      "    accuracy                           0.72       377\n",
      "   macro avg       0.74      0.69      0.69       377\n",
      "weighted avg       0.73      0.72      0.71       377\n",
      "\n",
      "\n",
      "k=20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76       220\n",
      "           1       0.69      0.43      0.53       157\n",
      "\n",
      "    accuracy                           0.68       377\n",
      "   macro avg       0.69      0.65      0.65       377\n",
      "weighted avg       0.69      0.68      0.67       377\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Reports of KNN classifiers on train set:\\n')\n",
    "print(f'k=5:\\n{sklearn.metrics.classification_report(y_train, y_pred)}\\n')\n",
    "print(f'k=10:\\n{sklearn.metrics.classification_report(y_train, y_pred10)}\\n')\n",
    "print(f'k=20:\\n{sklearn.metrics.classification_report(y_train, y_pred20)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466635b0",
   "metadata": {},
   "source": [
    "The model where k=5 performs best on our in-sample data. It has a higher accuracy and a higher F1 score than the models where k is equal to 10 or 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c422b",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on our out-of-sample data from `validate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4804ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifiers on validate set:\n",
      "\n",
      "KNN Accuracy where k=5: 0.6234567901234568\n",
      "KNN Accuracy where k=10: 0.654320987654321\n",
      "KNN Accuracy where k=20: 0.654320987654321\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifiers on validate set:\\n')\n",
    "print(f'KNN Accuracy where k=5: {knn.score(x_validate, y_validate)}')\n",
    "print(f'KNN Accuracy where k=10: {knn10.score(x_validate, y_validate)}')\n",
    "print(f'KNN Accuracy where k=20: {knn20.score(x_validate, y_validate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ff7a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports of KNN classifiers on validate set:\n",
      "\n",
      "k=5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68        94\n",
      "           1       0.56      0.51      0.53        68\n",
      "\n",
      "    accuracy                           0.62       162\n",
      "   macro avg       0.61      0.61      0.61       162\n",
      "weighted avg       0.62      0.62      0.62       162\n",
      "\n",
      "\n",
      "k=10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74        94\n",
      "           1       0.66      0.37      0.47        68\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.66      0.61      0.61       162\n",
      "weighted avg       0.66      0.65      0.63       162\n",
      "\n",
      "\n",
      "k=20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74        94\n",
      "           1       0.65      0.38      0.48        68\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.65      0.62      0.61       162\n",
      "weighted avg       0.65      0.65      0.63       162\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Reports of KNN classifiers on validate set:\\n')\n",
    "print(f'k=5:\\n{sklearn.metrics.classification_report(y_validate, knn.predict(x_validate))}\\n')\n",
    "print(f'k=10:\\n{sklearn.metrics.classification_report(y_validate, knn10.predict(x_validate))}\\n')\n",
    "print(f'k=20:\\n{sklearn.metrics.classification_report(y_validate, knn20.predict(x_validate))}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd4b7d",
   "metadata": {},
   "source": [
    "The model where k=20 performs best on the out-of-sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d6b77",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Exercises\n",
    "\n",
    "#### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2eaf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e7c640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression object\n",
    "logreg = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "862ed0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       220\n",
      "           1       0.67      0.54      0.59       157\n",
      "\n",
      "    accuracy                           0.69       377\n",
      "   macro avg       0.69      0.67      0.67       377\n",
      "weighted avg       0.69      0.69      0.69       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign dataframe with columns age, fare, and pclass to variable\n",
    "xtrain_afp = x_train[['age', 'fare', 'pclass']]\n",
    "\n",
    "# fit logreg to train, only with desired features\n",
    "logreg.fit(xtrain_afp, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(xtrain_afp)\n",
    "\n",
    "# print classification report\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17ef4f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 69.50%\n",
      "Baseline Accuracy: 58.36%\n"
     ]
    }
   ],
   "source": [
    "print(f'Model Accuracy: {logreg.score(xtrain_afp, y_train):.2%}')\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dd615",
   "metadata": {},
   "source": [
    "This model performs better than our baseline. The model has an accuracy of 69.5%, which is 11.4% greater than the baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1963e2",
   "metadata": {},
   "source": [
    "#### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "583f0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       220\n",
      "           1       0.77      0.73      0.75       157\n",
      "\n",
      "    accuracy                           0.80       377\n",
      "   macro avg       0.79      0.79      0.79       377\n",
      "weighted avg       0.80      0.80      0.80       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create copy of logistic regression object\n",
    "logreg2 = LogisticRegression(random_state=123)\n",
    "# filter down to desired features\n",
    "xtrain_safp = x_train[['sex_male', 'age', 'fare', 'pclass']]\n",
    "# fit logreg2\n",
    "logreg2.fit(xtrain_safp, y_train)\n",
    "# make predictions\n",
    "y_pred2 = logreg2.predict(xtrain_safp)\n",
    "# print classification report\n",
    "# print(sklearn.metrics.classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb53a4f",
   "metadata": {},
   "source": [
    "#### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ca060be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare  embark_town  \\\n",
       "513         1       1  female  54.0      1      0  59.4000    Cherbourg   \n",
       "169         0       3    male  28.0      0      0  56.4958  Southampton   \n",
       "276         0       3  female  45.0      0      0   7.7500  Southampton   \n",
       "541         0       3  female   9.0      4      2  31.2750  Southampton   \n",
       "406         0       3    male  51.0      0      0   7.7500  Southampton   \n",
       "\n",
       "     alone  embark_town_Queenstown  embark_town_Southampton  sex_male  \n",
       "513      0                       0                        0         0  \n",
       "169      1                       0                        1         1  \n",
       "276      1                       0                        1         0  \n",
       "541      0                       0                        1         0  \n",
       "406      1                       0                        1         1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84acf3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75       220\n",
      "           1       0.66      0.35      0.46       157\n",
      "\n",
      "    accuracy                           0.66       377\n",
      "   macro avg       0.66      0.61      0.60       377\n",
      "weighted avg       0.66      0.66      0.63       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg3 = LogisticRegression(random_state=123)\n",
    "xtrain_spa = x_train[['sibsp', 'parch', 'alone']]\n",
    "logreg3.fit(xtrain_spa, y_train)\n",
    "y_pred3 = logreg3.predict(xtrain_spa)\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "423d8dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       220\n",
      "           1       0.77      0.69      0.73       157\n",
      "\n",
      "    accuracy                           0.79       377\n",
      "   macro avg       0.78      0.77      0.78       377\n",
      "weighted avg       0.79      0.79      0.79       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg4 = LogisticRegression(random_state=123)\n",
    "xtrain_asp = x_train[['alone', 'sex_male', 'pclass']]\n",
    "logreg4.fit(xtrain_asp, y_train)\n",
    "y_pred4 = logreg4.predict(xtrain_asp)\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac5e4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       220\n",
      "           1       0.79      0.71      0.75       157\n",
      "\n",
      "    accuracy                           0.80       377\n",
      "   macro avg       0.80      0.79      0.79       377\n",
      "weighted avg       0.80      0.80      0.80       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg5 = LogisticRegression(C=0.1, random_state=123)\n",
    "logreg5.fit(xtrain_safp, y_train)\n",
    "y_pred5 = logreg5.predict(xtrain_safp)\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12d0056b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       220\n",
      "           1       0.79      0.71      0.75       157\n",
      "\n",
      "    accuracy                           0.80       377\n",
      "   macro avg       0.80      0.79      0.79       377\n",
      "weighted avg       0.80      0.80      0.80       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg6 = LogisticRegression(C=10, random_state=123)\n",
    "logreg6.fit(xtrain_safp, y_train)\n",
    "y_pred6 = logreg5.predict(xtrain_safp)\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16eb4a",
   "metadata": {},
   "source": [
    "#### 4. Use your best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524976f9",
   "metadata": {},
   "source": [
    "The best 3 models are logreg2 (80% accuracy), logreg4 (79% accuracy), and logreg5 (80% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e3ce44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg2 model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        94\n",
      "           1       0.79      0.74      0.76        68\n",
      "\n",
      "    accuracy                           0.81       162\n",
      "   macro avg       0.81      0.80      0.80       162\n",
      "weighted avg       0.81      0.81      0.81       162\n",
      "\n",
      "logreg4 model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.80        94\n",
      "           1       0.73      0.65      0.69        68\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.75      0.74      0.74       162\n",
      "weighted avg       0.75      0.75      0.75       162\n",
      "\n",
      "logreg5 model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85        94\n",
      "           1       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.81       162\n",
      "   macro avg       0.82      0.79      0.80       162\n",
      "weighted avg       0.81      0.81      0.80       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = logreg2.predict(x_validate[['sex_male', 'age', 'fare', 'pclass']])\n",
    "print('logreg2 model')\n",
    "print(sklearn.metrics.classification_report(y_validate, y_pred2))\n",
    "\n",
    "y_pred4 = logreg4.predict(x_validate[['alone', 'sex_male', 'pclass']])\n",
    "print('logreg4 model')\n",
    "print(sklearn.metrics.classification_report(y_validate, y_pred4))\n",
    "\n",
    "y_pred5 = logreg5.predict(x_validate[['sex_male', 'age', 'fare', 'pclass']])\n",
    "print('logreg5 model')\n",
    "print(sklearn.metrics.classification_report(y_validate, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb921a31",
   "metadata": {},
   "source": [
    "The logreg2 model appears to perform the best on the validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11876517",
   "metadata": {},
   "source": [
    "#### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38511bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg2 model on test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        79\n",
      "           1       0.69      0.68      0.68        56\n",
      "\n",
      "    accuracy                           0.74       135\n",
      "   macro avg       0.73      0.73      0.73       135\n",
      "weighted avg       0.74      0.74      0.74       135\n",
      "\n",
      "logreg2 model on validate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        94\n",
      "           1       0.79      0.74      0.76        68\n",
      "\n",
      "    accuracy                           0.81       162\n",
      "   macro avg       0.81      0.80      0.80       162\n",
      "weighted avg       0.81      0.81      0.81       162\n",
      "\n",
      "logreg2 model on train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       220\n",
      "           1       0.77      0.73      0.75       157\n",
      "\n",
      "    accuracy                           0.80       377\n",
      "   macro avg       0.79      0.79      0.79       377\n",
      "weighted avg       0.80      0.80      0.80       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg2.predict(x_test[['sex_male', 'age', 'fare', 'pclass']])\n",
    "print('logreg2 model on test')\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = logreg2.predict(x_validate[['sex_male', 'age', 'fare', 'pclass']])\n",
    "print('logreg2 model on validate')\n",
    "print(sklearn.metrics.classification_report(y_validate, y_pred))\n",
    "\n",
    "y_pred = logreg2.predict(x_train[['sex_male', 'age', 'fare', 'pclass']])\n",
    "print('logreg2 model on train')\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0428505",
   "metadata": {},
   "source": [
    "This model performs best on the validate sample. It performed better on the train sample than it did on the test sample. The model had the lowest performance on the test sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
